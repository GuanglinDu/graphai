{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "global-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created on Mar 21, 2021 Sun\n",
    "# Python For Data Science Cheat Sheet - keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriented-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.53330262 0.94866294 0.91960644 0.10397062 0.17145148 0.78164588\n",
      "  0.1730111  0.40485904 0.99102547 0.59759749 0.59310849 0.76124884\n",
      "  0.06038032 0.68254937 0.95755267 0.07583314 0.46505206 0.88994572\n",
      "  0.07266415 0.73125962 0.6282656  0.84545465 0.16435248 0.72589153\n",
      "  0.7443574  0.01513034 0.4380371  0.94112518 0.32973892 0.9513263\n",
      "  0.81910662 0.77497604 0.6232764  0.12705857 0.40468887 0.06480321\n",
      "  0.74277689 0.73564863 0.3939432  0.16767872 0.70392246 0.43209229\n",
      "  0.5324772  0.71132462 0.88954023 0.24989956 0.38460261 0.15130753\n",
      "  0.22639513 0.67101755 0.51905542 0.34491668 0.03200705 0.91146422\n",
      "  0.58352371 0.81953271 0.01148236 0.08936535 0.06678692 0.21437482\n",
      "  0.47757087 0.93936457 0.52132248 0.14546631 0.08408746 0.58831102\n",
      "  0.14979047 0.40154762 0.34763297 0.64984197 0.96571173 0.78904481\n",
      "  0.90385993 0.3298323  0.2168597  0.47113626 0.50717314 0.70498337\n",
      "  0.49670931 0.44776203 0.73602952 0.17248069 0.27670731 0.70110503\n",
      "  0.39946717 0.57417397 0.22269821 0.98340639 0.83918011 0.6929103\n",
      "  0.42842902 0.86945152 0.42772001 0.66600966 0.70257432 0.71608643\n",
      "  0.75115091 0.19724958 0.50846711 0.60423214]\n",
      " [0.17495457 0.40253392 0.57864433 0.4100728  0.95853356 0.10614692\n",
      "  0.93410946 0.60678502 0.61415726 0.32194527 0.79969786 0.02685062\n",
      "  0.16118952 0.47920604 0.55561464 0.4569536  0.66557279 0.31144983\n",
      "  0.26569124 0.1737048  0.69911554 0.07461545 0.17963368 0.21090745\n",
      "  0.67015891 0.94984536 0.20009628 0.0708056  0.40084349 0.69773417\n",
      "  0.96261493 0.42513698 0.44535769 0.94362891 0.79383707 0.53233588\n",
      "  0.87257729 0.02688639 0.52050213 0.68940675 0.53765687 0.05787002\n",
      "  0.13269007 0.578768   0.59584845 0.60716727 0.37201135 0.78232159\n",
      "  0.40070049 0.61482275 0.46171494 0.93421977 0.09576185 0.43304811\n",
      "  0.99398975 0.33540903 0.10094989 0.57845882 0.17241286 0.5067217\n",
      "  0.5695238  0.49277564 0.12044554 0.01117968 0.70723262 0.81003757\n",
      "  0.17310605 0.98851111 0.51790827 0.8989928  0.28656257 0.10123764\n",
      "  0.51627344 0.69656409 0.19006737 0.65590076 0.910595   0.24847724\n",
      "  0.64381407 0.11182447 0.33629654 0.81771634 0.25057115 0.13078153\n",
      "  0.0593674  0.49812504 0.08194071 0.92415685 0.91129022 0.62862652\n",
      "  0.89280471 0.61391013 0.74573225 0.99363111 0.162117   0.33443238\n",
      "  0.32907637 0.74328891 0.90388543 0.48183589]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "print(type(data))\n",
    "print(data[0:2])\n",
    "print(type(labels))\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abstract-issue",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.7005 - accuracy: 0.5016\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.6943 - accuracy: 0.5409\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.6832 - accuracy: 0.5636\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.6807 - accuracy: 0.5610\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.6757 - accuracy: 0.5836\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.6726 - accuracy: 0.5666\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.6580 - accuracy: 0.6249\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.6610 - accuracy: 0.6157\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.6586 - accuracy: 0.6197\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.6427 - accuracy: 0.6401\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.6536 - accuracy: 0.6166\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.6399 - accuracy: 0.6449\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.6373 - accuracy: 0.6392\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6647\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.6414 - accuracy: 0.6468\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.6255 - accuracy: 0.6807\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.6262 - accuracy: 0.6742\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.6166 - accuracy: 0.6593\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.6146 - accuracy: 0.6933\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.6125 - accuracy: 0.6822\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6524\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.6097 - accuracy: 0.6522\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.6061 - accuracy: 0.6816\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.6132 - accuracy: 0.6615\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.6020 - accuracy: 0.6755\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.5966 - accuracy: 0.6740\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.5874 - accuracy: 0.7236\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.5899 - accuracy: 0.7226\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.6997\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.5879 - accuracy: 0.7018\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.5813 - accuracy: 0.7013\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.5793 - accuracy: 0.7007\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.5824 - accuracy: 0.6930\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.5851 - accuracy: 0.7073\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7193\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7149\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.5699 - accuracy: 0.7161\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.5556 - accuracy: 0.7336\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.5670 - accuracy: 0.7184\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.5588 - accuracy: 0.7369\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.5466 - accuracy: 0.7556\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.5602 - accuracy: 0.7296\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.5489 - accuracy: 0.7344\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.5490 - accuracy: 0.7368\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7541\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7539\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.5463 - accuracy: 0.7284\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.5367 - accuracy: 0.7357\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.5294 - accuracy: 0.7536\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.5274 - accuracy: 0.7565\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.5080 - accuracy: 0.7874\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.5072 - accuracy: 0.7822\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.5137 - accuracy: 0.7487\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.5030 - accuracy: 0.7666\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.5059 - accuracy: 0.7685\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.5001 - accuracy: 0.7938\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.4932 - accuracy: 0.7845\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.5034 - accuracy: 0.7916\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.4790 - accuracy: 0.8074\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.4998 - accuracy: 0.7839\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.4635 - accuracy: 0.8134\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.4691 - accuracy: 0.8137\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7970\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.4679 - accuracy: 0.7974\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.4630 - accuracy: 0.8133\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.4609 - accuracy: 0.8142\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.8037\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.4601 - accuracy: 0.8146\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.4514 - accuracy: 0.8194\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8404\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.4314 - accuracy: 0.8401\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.4422 - accuracy: 0.8312\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.4219 - accuracy: 0.8413\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8516\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.4199 - accuracy: 0.8504\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8569\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8498\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.4039 - accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.4104 - accuracy: 0.8498\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.4043 - accuracy: 0.8600\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.4087 - accuracy: 0.8587\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.3922 - accuracy: 0.8606\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.3896 - accuracy: 0.8636\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.3801 - accuracy: 0.8787\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.3902 - accuracy: 0.8665\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.3924 - accuracy: 0.8600\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.3824 - accuracy: 0.8722\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.3717 - accuracy: 0.8886\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.3579 - accuracy: 0.8877\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.3643 - accuracy: 0.8959\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.9023\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.3548 - accuracy: 0.9080\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.3744 - accuracy: 0.8645\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.3438 - accuracy: 0.8905\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.3393 - accuracy: 0.9029\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.3339 - accuracy: 0.8930\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.3337 - accuracy: 0.9098\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.3466 - accuracy: 0.8858\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.3305 - accuracy: 0.8968\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.3387 - accuracy: 0.8956\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.9087\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.3116 - accuracy: 0.9240\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.3200 - accuracy: 0.9055\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.3089 - accuracy: 0.9109\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.3011 - accuracy: 0.9212\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.3015 - accuracy: 0.9110\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.3011 - accuracy: 0.9338\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.2931 - accuracy: 0.9347\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.3027 - accuracy: 0.9180\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.9119\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.2793 - accuracy: 0.9390\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.9251\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2852 - accuracy: 0.9308\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.2792 - accuracy: 0.9421\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.2816 - accuracy: 0.9400\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2794 - accuracy: 0.9288\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.9491\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.2703 - accuracy: 0.9326\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2505 - accuracy: 0.9418\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.2742 - accuracy: 0.9389\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2565 - accuracy: 0.9343\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.2501 - accuracy: 0.9460\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.9263\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2513 - accuracy: 0.9374\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.2555 - accuracy: 0.9382\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.2386 - accuracy: 0.9549\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9524\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.2306 - accuracy: 0.9677\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9492\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.2310 - accuracy: 0.9647\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9523\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.2260 - accuracy: 0.9659\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2252 - accuracy: 0.9512\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2108 - accuracy: 0.9600\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.2089 - accuracy: 0.9649\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.2018 - accuracy: 0.9702\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.2048 - accuracy: 0.9768\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2012 - accuracy: 0.9618\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.2085 - accuracy: 0.9663\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.2201 - accuracy: 0.9489\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1970 - accuracy: 0.9705\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1901 - accuracy: 0.9779\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1899 - accuracy: 0.9763\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1955 - accuracy: 0.9747\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1986 - accuracy: 0.9633\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1895 - accuracy: 0.9830\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1859 - accuracy: 0.9734\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1784 - accuracy: 0.9766\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1810 - accuracy: 0.9793\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1754 - accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a38356100>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(data, labels, epochs=150, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fluid-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.04415807]\n",
      " [0.49322176]\n",
      " [0.6610975 ]\n",
      " [0.3152902 ]\n",
      " [0.01876357]\n",
      " [0.0441829 ]\n",
      " [0.10838068]\n",
      " [0.9596227 ]\n",
      " [0.06065029]\n",
      " [0.02187818]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(data)\n",
    "print(type(predictions))\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-earthquake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
